image: ${BENCHMARKS_REGISTRY}/${BENCHMARKS_CONTAINER}:${BENCHMARKS_TAG}

variables:
  RECO: "eicrecon"
  DETECTOR: epic
  DETECTOR_CONFIG: epic_craterlake

workflow:
  name: '$PIPELINE_NAME'

default:
  before_script:
    - source .local/bin/env.sh
  tags:
    - phy-scratch
  artifacts:
    expire_in: 3 days
    paths:
      - .local/detector
      - .local/lib
      - .local/bin
      - .local/include
      - .local/share
      - .local/root_build
      - .snakemake/log
      - results
      - config
      - .env
      - summary.txt
    reports:
      dotenv: .env

stages:
  - status-pending
  - config
  - compile
  - generate
  - simulate
  - collect
  - finish
  - status-report

.status:
  image: curlimages/curl:latest
  before_script: []
  script:
    - |
      if [ -n "${GITHUB_SHA}" ] ; then
        curl \
          -X POST \
          -H "Accept: application/vnd.github+json" \
          -H "Authorization: token ${GITHUB_REPO_STATUS_TOKEN}" \
          "https://api.github.com/repos/${GITHUB_REPOSITORY}/statuses/${GITHUB_SHA}" \
          -d '{"state":"'"${STATE}"'",
               "target_url":"'"${CI_PIPELINE_URL}"'",
               "description":"'"${DESCRIPTION} $(TZ=America/New_York date)"'",
               "context":"eicweb/physics_benchmarks ('"$DETECTOR_CONFIG"')"
              }' ;
      fi

benchmarks:physics:pending:
  stage: status-pending
  extends: .status
  variables:
    STATE: "pending"
    DESCRIPTION: "Started..."
  when: always

common:setup:
  stage: config
  before_script:
    - |
      if [[ -z "${COMMON_BENCH_VERSION}" ]] ; then
        export COMMON_BENCH_VERSION="master" 
      fi
      echo "COMMON_BENCH_VERSION = ${COMMON_BENCH_VERSION}" 
      echo "COMMON_BENCH_VERSION=${COMMON_BENCH_VERSION}" >> .env
  script:
    - git clone -b "${COMMON_BENCH_VERSION}" https://eicweb.phy.anl.gov/EIC/benchmarks/common_bench.git setup 
    - source setup/bin/env.sh && ./setup/bin/install_common.sh
    - mkdir_local_data_link sim_output
    - mkdir_local_data_link datasets
    - mkdir -p results
    - mkdir -p config
    - print_env.sh

.compile_benchmark:
  needs:
    - ["common:setup"]
  before_script:
    - source .local/bin/env.sh  

.phy_benchmark:
  needs:
    - ["common:setup"]
  before_script:
    - source .local/bin/env.sh
    - source /opt/detector/epic-main/setup.sh
    - ls -lrtha 
    - ln -s "${LOCAL_DATA_PATH}/sim_output" sim_output
    - ln -s "${LOCAL_DATA_PATH}/datasets/data" data
    - mkdir -p "$SNAKEMAKE_OUTPUT_CACHE"
    - ls -lrtha
  retry:
    max: 2
    when:
      - runner_system_failure

include:
  - local: 'benchmarks/backgrounds/config.yml'
  - local: 'benchmarks/Exclusive-Diffraction-Tagging/diffractive_vm/config.yml'
  - local: 'benchmarks/Exclusive-Diffraction-Tagging/demp/config.yml'
    #- local: 'benchmarks/Exclusive-Diffraction-Tagging/dvmp/config.yml'
  - local: 'benchmarks/Exclusive-Diffraction-Tagging/dvcs/config.yml'
  - local: 'benchmarks/Exclusive-Diffraction-Tagging/tcs/config.yml'
  - local: 'benchmarks/Exclusive-Diffraction-Tagging/u_omega/config.yml'
  - local: 'benchmarks/Inclusive/dis/config.yml'

summary:
  stage: finish
  needs:
    - "diffractive_vm:results"
    - "demp:results"
    - "dis:results"
    - "dvcs:results"
    - "tcs:results"
    - "u_omega:results"
    - "backgrounds:results"
  script:
    - collect_benchmarks.py
    - find results -print | sort | tee summary.txt
  artifacts:
    paths:
      - summary.txt
      - results/*
#    reports:
#      junit: ["results/dvcs/report2.xml"]

benchmarks:physics:success:
  stage: status-report
  dependencies: []
  extends: .status
  variables:
    STATE: "success"
    DESCRIPTION: "Succeeded!"
  after_script:
    # Cleanup scratch space
    - rm -rfv $LOCAL_DATA_PATH
  when: on_success

benchmarks:physics:failure:
  stage: status-report
  dependencies: []
  extends: .status
  variables:
    STATE: "failure"
    DESCRIPTION: "Failed!"
  when: on_failure
