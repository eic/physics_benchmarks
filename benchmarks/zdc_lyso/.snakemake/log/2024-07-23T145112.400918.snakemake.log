Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                   count    min threads    max threads
------------------  -------  -------------  -------------
semi_coherent_reco        1              1              1
semi_coherent_sim         1              1              1
total                     2              1              1

Select jobs to execute...

[Tue Jul 23 14:51:14 2024]
rule semi_coherent_sim:
    input: input.hepmc
    output: data/epic_semi_coherent.edm4hep.root
    log: log/epic_semi_coherent.edm4hep.root.log
    jobid: 1
    reason: Missing output files: data/epic_semi_coherent.edm4hep.root
    wildcards: DETECTOR_CONFIG=epic
    resources: tmpdir=/tmp

[Tue Jul 23 15:05:51 2024]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...

[Tue Jul 23 15:05:51 2024]
rule semi_coherent_reco:
    input: data/epic_semi_coherent.edm4hep.root
    output: data/epic_semi_coherent.eicrecon.tree.edm4eic.root
    log: log/epic_semi_coherent.eicrecon.tree.edm4eic.root.log
    jobid: 0
    reason: Missing output files: data/epic_semi_coherent.eicrecon.tree.edm4eic.root; Input files updated by another job: data/epic_semi_coherent.edm4hep.root
    wildcards: DETECTOR_CONFIG=epic
    resources: tmpdir=/tmp

[Tue Jul 23 15:06:17 2024]
Finished job 0.
2 of 2 steps (100%) done
Complete log: .snakemake/log/2024-07-23T145112.400918.snakemake.log
